seed: 42
device: "mps"
precision: "bf16"           # "fp16" | "bf16" | "fp32"

# data
train_csv: "data/breast_tumors_ct_scan_train.csv"
val_csv: "data/breast_tumors_ct_scan_test.csv"
image_root: "data"   # base for images if your CSV stores relative paths
mask_root: "data"     # base for masks if your CSV stores only image_name
img_size: 1024
center_thresh_frac: 0.1     # near-center threshold (paper uses a distance threshold)  # :contentReference[oaicite:5]{index=5}
num_workers: 8

# model
vision:
  name: "tiny_vit_21m_224"  # TinyViT as TinySAM-style backbone; can be swapped
  pretrained: true
  out_dim: 256              # spatial channels after projection
  freeze: false             # paper keeps TinySAM trainable for best results  # :contentReference[oaicite:6]{index=6}

llm:
  model_id: "llava-hf/llava-v1.6-mistral-7b"
  lora:
    r: 16
    alpha: 16
    dropout: 0.05
    target_modules: ["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"]

fusion:
  proj_dim: 256
  n_heads: 8

decoder:
  up_channels: [256, 128, 64, 32, 16]

# training
train:
  epochs: 20
  batch_size: 4
  lr: 1.0e-4
  weight_decay: 1.0e-4
  grad_accum_steps: 2
  log_every: 50
  ckpt_dir: "checkpoints"

# loss weights
loss:
  lambda_seg: 1.0
  lambda_txt: 1.0

# text generation
gen:
  max_new_tokens: 48
  temperature: 0.2
